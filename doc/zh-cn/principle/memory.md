# Memory 模块

## 1. 介绍

记忆（Memory）模块是 Chat2Graph 框架中负责信息存储、检索和管理的核心组件，基于 DIKW（Data-Information-Knowledge-Wisdom）模型设计。该模块旨在为系统提供跨会话的记忆能力、信息评估、经验提取和洞察生成功能，从而提升系统整体的智能水平。

<div style="text-align: center;">
  <img src="../../asset/image/memory-arch.png" alt="memory-architecture" width="80%">
</div>

记忆模块通过多层级的记忆架构，定义了从原始数据逐步提炼到高层次的智慧洞察等记忆模块中的概念，为整个 Chat2Graph 系统提供持久化的学习和适应能力。

## 2. DIKW 记忆模块设计

### 2.1. 分层记忆架构

记忆模块采用经典的 DIKW 金字塔模型，将记忆内容按抽象层次分为四个等级：

| 层级 | 名称 | 描述 | 存储内容 | 典型用途 |
|:----:|:-----|:-----|:---------|:---------|
| **L0** | **History (Data)** | 原始数据存储层 | 会话历史、工具调用记录、系统日志等 | 完整追溯、调试分析、基础检索 |
| **L1** | **Evaluation (Information)** | 信息处理层 | 评估结果、性能指标、状态分类等 | 质量控制、错误诊断、模式识别 |
| **L2** | **Lesson (Knowledge)** | 知识抽取层 | 经验规则、最佳实践、领域知识等 | 决策支持、策略优化、技能传承 |
| **L3** | **Insight (Wisdom)** | 智慧洞察层 | 高层决策模式、战略洞察等 | 跨会话决策、用户偏好、流程优化 |

### 2.2. 层级间的信息流动

各层级之间通过**信息提升**（Information Escalation）和**横向应用**（Horizontal Application）两个过程实现动态交互：

- **向上提升**：原始数据经过处理、分析和抽象，逐步转化为更高层次的知识和智慧
- **横向应用**：除了垂直的信息流动外，横向记忆应用，将不同层级的记忆内容直接注入到 Chat2Graph 的各个执行模块中（`Session`、`Agent`、`Workflow` 和 
 `Reasoner`），用于提升 LLM 的生成效果和决策质量。

### 2.3. 缓冲系统架

记忆模块（由 MemFuse 实现）采用多缓冲区架构，确保"低延迟"的实时处理能力。缓冲系统作为透明的中间组件，主要负责加速处理，不影响 DIKW 分层记忆的核心逻辑和数据流程。三个缓冲区按照数据流向形成层级关系：`Write Buffer` 负责数据入口和预处理，`Speculative Buffer` 基于预测算法进行智能缓存，`Query Buffer` 直接响应检索请求并提供结果。`Buffer Manager` 协调三个缓冲区的工作，通过层级调度机制确保数据在不同层级间的有序流动和高效处理。

```
                    ┌─────────────────┐
                    │ Buffer Manager  │
                    │                 │
                    │ • 系统协调       │
                    │ • 负载均衡       │
                    │ • 一致性保证     │
                    │ • 层级调度       │
                    └─────────┬───────┘
                              │ 管理协调
              ┌───────────────┼───────────────┐
              │               │               │
    ┌─────────▼─────────┐ ┌───▼─────────────┐ ┌▼─────────────────┐
    │   Write Buffer    │ │ Speculative     │ │   Query Buffer   │
    │     (L1)          │ │   Buffer (L2)   │ │      (L3)        │
    │ • 批量写入          │ │ • 预测缓存       │ │ • 检索管理        │
    │ • 异步处理          │ │ • 智能预取       │ │ • 结果缓存        │
    │ • 数据压缩          │ │ • 上下文感知     │ │ • 相关性排序       │
    └─────────┬─────────┘ └─────────┬───────┘ └──────────────────┘
              │                     │
              └─────────────────────┘
                    层级协作（待定）
```

三个缓冲区按处理优先级和数据流向形成层级关系：

1. **Write Buffer (L1)**：作为数据入口层，负责接收和预处理原始记忆数据
2. **Speculative Buffer (L2)**：作为智能中间层，基于预测算法进行数据预取和缓存优化
3. **Query Buffer (L3)**：作为服务输出层，直接响应检索请求并提供最终结果

## 3. 环境设计

在 Chat2Graph 框架中，环境（Environment）被定义为 Agent 执行过程中可交互的外部状态空间。Agent 既可以通过工具操作来影响环境状态，也可以通过信息获取来感知环境变化。更重要的是，我们认为环境和记忆在本质上是同质的概念——它们都是信息的载体和状态的表征，只是在时间维度和访问方式上存在差异。

环境可以被视为"当前时刻的外部记忆"，而记忆则是"历史时刻的环境快照"。这种同质性体现在它们共同的信息本质：环境状态包含的文件系统、数据库记录、网络资源等，本质上都是结构化或非结构化的信息实体，与记忆系统中存储的历史数据、评估结果、经验知识在形式和功能上高度相似。

这种同质性使得环境信息可以无缝地融入到 DIKW 记忆模型中。当 Agent 通过工具读取环境信息时，这些信息会自动进入 L0 层作为原始数据；当 Agent 的操作改变环境状态时，这种变化会被记录为历史事件，并可能经过抽象提炼形成更高层次的知识和洞察。反过来，记忆系统中积累的历史经验和模式识别结果，会直接指导 Agent 对当前环境的理解、预测和操作策略。

从信息流动的角度看，环境与记忆形成了一个闭环系统：环境状态通过感知转化为记忆内容，记忆内容通过决策影响环境操作，环境操作的结果又成为新的环境状态。这种循环不仅实现了 Agent 与外界的持续交互，更重要的是建立了一个自我强化的学习机制，使系统能够在与环境的互动中不断积累智慧，提升适应能力。

Chat2Graph 希望统一记忆管理与环境感知，为 Agent 提供了连贯的认知基础，使其能够在复杂多变的环境中保持一致性和连续性的智能行为。

## 4. 未来扩展

### 4.1. 记忆编辑

支持对已存储的记忆内容进行动态修改和更新，包括错误纠正、内容补充和重要性调整，比如插入用户偏好，注入知识等。

### 4.2. 自适应遗忘

开发更智能的遗忘机制，根据记忆的重要性、使用频率和时效性动态调整保留策略。系统将能够自动识别过时或低价值的记忆内容。

### 4.3. 多模态记忆

扩展支持图像、视频等多模态记忆内容，增强系统的感知和理解能力。这将使 Chat2Graph 能够处理更丰富的信息类型，提供更全面的记忆服务。
